# Processing massive datasets
## Exercise 6 - MapReduce in Spark

Result files are as dictionary with raw text files inside.
You should see few files - parts of result.
In dictionary also special file `_SUCCESS` generated by `Hadoop` to show - processing process finished.

`reduceByKey` is required to enable reduction (in MapReduce paradigm) - this `+` is required action.
We need calculate sum of words counts in file.
