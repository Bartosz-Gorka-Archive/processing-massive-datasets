# Processing massive datasets
Processing massive datasets - Poznan University of Technology, study project

## Stats
Check files `{NUMBER_OF_ITERATIONS}_iterations.txt` in `stats` directory to verify each iteration.

### 10 iterations
```python
Terrorist * day
	MIN: 2411
	AVERAGE: 2458.1
	MEDIAN: 2462.5
	MAX: 2504

Unique terrorist count
	MIN: 3583
	AVERAGE: 3633.3
	MEDIAN: 3631.5
	MAX: 3711

Histogram stats
	1: MIN 491682 	| AVG 493737.7 	| MEDIAN 493418.0 	| MAX 495497
	2: MIN 2393 	| AVG 2436.5 	| MEDIAN 2440.0 	| MAX 2480
	3: MIN 3 	| AVG 7.2 	| MEDIAN 7.0 		| MAX 10
```

### 100 iterations
```python
Terrorist * day
	MIN: 2347
	AVERAGE: 2476.1
	MEDIAN: 2471.5
	MAX: 2621

Unique terrorist count
	MIN: 3456
	AVERAGE: 3631.95
	MEDIAN: 3636.5
	MAX: 3766

Histogram stats
	1: MIN 487103 	| AVG 494870.9 	| MEDIAN 494876.0 	| MAX 503203
	2: MIN 2317 	| AVG 2452.52 	| MEDIAN 2451.5 	| MAX 2591
	3: MIN 2 	| AVG 7.86 	| MEDIAN 8.0 		| MAX 17
```

### 1000 iterations
```python
Terrorist * day
	MIN: 2306
	AVERAGE: 2472.541
	MEDIAN: 2472.0
	MAX: 2664

Unique terrorist count
	MIN: 3425
	AVERAGE: 3630.81
	MEDIAN: 3630.0
	MAX: 3887

Histogram stats
	1: MIN 486097 	| AVG 495194.623 	| MEDIAN 495163.5 	| MAX 503988
	2: MIN 2285 	| AVG 2448.538 		| MEDIAN 2449.0 	| MAX 2646
	3: MIN 1 	| AVG 7.981 		| MEDIAN 8.0 		| MAX 20
	4: MIN 1 	| AVG 1.0 		| MEDIAN 1.0 		| MAX 1
```
